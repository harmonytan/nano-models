"""
Qwen3æ¨¡å‹è®­ç»ƒç¤ºä¾‹
"""
import torch
import torch.nn as nn
import torch.optim as optim
from qwen3_trainer import Qwen3Trainer, SimpleTokenizer, TextDataset
from ..model.qwen3 import Qwen3Config, Qwen3Transformer


def create_sample_texts():
    """åˆ›å»ºç¤ºä¾‹è®­ç»ƒæ–‡æœ¬"""
    sample_texts = [
        "äººå·¥æ™ºèƒ½æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œå®ƒä¼å›¾äº†è§£æ™ºèƒ½çš„å®è´¨ï¼Œå¹¶ç”Ÿäº§å‡ºä¸€ç§æ–°çš„èƒ½ä»¥äººç±»æ™ºèƒ½ç›¸ä¼¼çš„æ–¹å¼åšå‡ºååº”çš„æ™ºèƒ½æœºå™¨ã€‚",
        "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªå­é›†ï¼Œå®ƒä½¿ç”¨ç»Ÿè®¡å­¦æ–¹æ³•è®©è®¡ç®—æœºç³»ç»Ÿèƒ½å¤Ÿè‡ªåŠ¨å­¦ä¹ å’Œæ”¹è¿›ï¼Œè€Œæ— éœ€æ˜ç¡®ç¼–ç¨‹ã€‚",
        "æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œå®ƒä½¿ç”¨å¤šå±‚ç¥ç»ç½‘ç»œæ¥æ¨¡æ‹Ÿäººè„‘çš„å­¦ä¹ è¿‡ç¨‹ï¼Œèƒ½å¤Ÿè‡ªåŠ¨å­¦ä¹ ç‰¹å¾è¡¨ç¤ºã€‚",
        "è‡ªç„¶è¯­è¨€å¤„ç†æ˜¯äººå·¥æ™ºèƒ½å’Œè¯­è¨€å­¦é¢†åŸŸçš„åˆ†æ”¯å­¦ç§‘ï¼Œå®ƒç ”ç©¶äººä¸è®¡ç®—æœºä¹‹é—´ç”¨è‡ªç„¶è¯­è¨€è¿›è¡Œæœ‰æ•ˆé€šä¿¡çš„å„ç§ç†è®ºå’Œæ–¹æ³•ã€‚",
        "è®¡ç®—æœºè§†è§‰æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œå®ƒä½¿è®¡ç®—æœºèƒ½å¤Ÿç†è§£å’Œåˆ†æè§†è§‰ä¿¡æ¯ï¼Œå¦‚å›¾åƒå’Œè§†é¢‘ã€‚",
        "å¼ºåŒ–å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ç§æ–¹æ³•ï¼Œå®ƒé€šè¿‡ä¸ç¯å¢ƒäº¤äº’æ¥å­¦ä¹ æœ€ä¼˜çš„è¡Œä¸ºç­–ç•¥ã€‚",
        "ç¥ç»ç½‘ç»œæ˜¯ä¸€ç§æ¨¡ä»¿ç”Ÿç‰©ç¥ç»ç³»ç»Ÿçš„è®¡ç®—æ¨¡å‹ï¼Œç”±å¤§é‡ç›¸äº’è¿æ¥çš„ç¥ç»å…ƒç»„æˆã€‚",
        "å·ç§¯ç¥ç»ç½‘ç»œæ˜¯ä¸€ç§ä¸“é—¨ç”¨äºå¤„ç†å…·æœ‰ç½‘æ ¼ç»“æ„æ•°æ®çš„ç¥ç»ç½‘ç»œï¼Œå¦‚å›¾åƒæ•°æ®ã€‚",
        "å¾ªç¯ç¥ç»ç½‘ç»œæ˜¯ä¸€ç§ä¸“é—¨ç”¨äºå¤„ç†åºåˆ—æ•°æ®çš„ç¥ç»ç½‘ç»œï¼Œèƒ½å¤Ÿä¿æŒçŠ¶æ€ä¿¡æ¯ã€‚",
        "Transformeræ˜¯ä¸€ç§åŸºäºæ³¨æ„åŠ›æœºåˆ¶çš„ç¥ç»ç½‘ç»œæ¶æ„ï¼Œåœ¨è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ã€‚",
        "æ³¨æ„åŠ›æœºåˆ¶æ˜¯æ·±åº¦å­¦ä¹ ä¸­çš„ä¸€ç§é‡è¦æŠ€æœ¯ï¼Œå®ƒå…è®¸æ¨¡å‹å…³æ³¨è¾“å…¥æ•°æ®çš„ä¸åŒéƒ¨åˆ†ã€‚",
        "é¢„è®­ç»ƒæ¨¡å‹æ˜¯åœ¨å¤§è§„æ¨¡æ•°æ®ä¸Šé¢„å…ˆè®­ç»ƒçš„æ¨¡å‹ï¼Œå¯ä»¥é€šè¿‡å¾®è°ƒé€‚åº”ç‰¹å®šä»»åŠ¡ã€‚",
        "è¿ç§»å­¦ä¹ æ˜¯å°†åœ¨ä¸€ä¸ªä»»åŠ¡ä¸Šå­¦åˆ°çš„çŸ¥è¯†åº”ç”¨åˆ°å¦ä¸€ä¸ªç›¸å…³ä»»åŠ¡ä¸Šçš„æŠ€æœ¯ã€‚",
        "æ•°æ®å¢å¼ºæ˜¯é€šè¿‡å¯¹ç°æœ‰æ•°æ®è¿›è¡Œå˜æ¢æ¥å¢åŠ è®­ç»ƒæ•°æ®é‡çš„æŠ€æœ¯ã€‚",
        "æ­£åˆ™åŒ–æ˜¯é˜²æ­¢æœºå™¨å­¦ä¹ æ¨¡å‹è¿‡æ‹Ÿåˆçš„æŠ€æœ¯ï¼ŒåŒ…æ‹¬L1ã€L2æ­£åˆ™åŒ–ç­‰ã€‚",
        "æ¢¯åº¦ä¸‹é™æ˜¯ä¼˜åŒ–ç¥ç»ç½‘ç»œå‚æ•°çš„åŸºæœ¬ç®—æ³•ï¼Œé€šè¿‡è®¡ç®—æ¢¯åº¦æ¥æ›´æ–°å‚æ•°ã€‚",
        "åå‘ä¼ æ’­æ˜¯è®­ç»ƒç¥ç»ç½‘ç»œçš„æ ¸å¿ƒç®—æ³•ï¼Œç”¨äºè®¡ç®—æ¢¯åº¦ã€‚",
        "æ¿€æ´»å‡½æ•°æ˜¯ç¥ç»ç½‘ç»œä¸­çš„éçº¿æ€§å‡½æ•°ï¼Œå¦‚ReLUã€Sigmoidã€Tanhç­‰ã€‚",
        "æ‰¹é‡å½’ä¸€åŒ–æ˜¯ä¸€ç§åŠ é€Ÿç¥ç»ç½‘ç»œè®­ç»ƒçš„æŠ€æœ¯ï¼Œé€šè¿‡å½’ä¸€åŒ–æ¿€æ´»å€¼æ¥ç¨³å®šè®­ç»ƒã€‚",
        "Dropoutæ˜¯ä¸€ç§é˜²æ­¢è¿‡æ‹Ÿåˆçš„æŠ€æœ¯ï¼Œåœ¨è®­ç»ƒæ—¶éšæœºä¸¢å¼ƒä¸€äº›ç¥ç»å…ƒã€‚"
    ]
    return sample_texts


def main():
    """ä¸»å‡½æ•°ï¼šæ¼”ç¤ºå¦‚ä½•è®­ç»ƒQwen3æ¨¡å‹"""
    print("ğŸš€ å¼€å§‹Qwen3æ¨¡å‹è®­ç»ƒæ¼”ç¤º...")
    
    # 1. åˆ›å»ºç¤ºä¾‹æ–‡æœ¬æ•°æ®
    print("\nğŸ“ å‡†å¤‡è®­ç»ƒæ•°æ®...")
    sample_texts = create_sample_texts()
    print(f"åˆ›å»ºäº† {len(sample_texts)} æ¡ç¤ºä¾‹æ–‡æœ¬")
    
    # 2. åˆ›å»ºåˆ†è¯å™¨
    print("\nğŸ”¤ åˆå§‹åŒ–åˆ†è¯å™¨...")
    tokenizer = SimpleTokenizer(vocab_size=1000)
    
    # 3. åˆ›å»ºæ•°æ®é›†
    print("\nğŸ“Š åˆ›å»ºè®­ç»ƒæ•°æ®é›†...")
    dataset = TextDataset(sample_texts, tokenizer, max_length=128)
    print(f"æ•°æ®é›†å¤§å°: {len(dataset)}")
    
    # 4. åˆ›å»ºQwen3æ¨¡å‹é…ç½®
    print("\nğŸ—ï¸ åˆ›å»ºQwen3æ¨¡å‹...")
    config = Qwen3Config.from_preset('tiny')  # ä½¿ç”¨æœ€å°çš„æ¨¡å‹é…ç½®è¿›è¡Œæ¼”ç¤º
    print(f"æ¨¡å‹é…ç½®: {config}")
    
    # 5. åˆ›å»ºQwen3æ¨¡å‹
    model = Qwen3Transformer(config)
    print(f"æ¨¡å‹åˆ›å»ºå®Œæˆï¼Œå‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")
    
    # 6. åˆ›å»ºä¼˜åŒ–å™¨å’ŒæŸå¤±å‡½æ•°
    print("\nâš™ï¸ è®¾ç½®è®­ç»ƒç»„ä»¶...")
    optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)
    criterion = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)
    
    # 7. åˆ›å»ºQwen3è®­ç»ƒå™¨
    print("\nğŸ¯ åˆå§‹åŒ–Qwen3è®­ç»ƒå™¨...")
    trainer = Qwen3Trainer(
        model=model,
        dataset=dataset,
        tokenizer=tokenizer,
        optimizer=optimizer,
        criterion=criterion,
        batch_size=2,  # å°æ‰¹æ¬¡å¤§å°ï¼Œé€‚åˆæ¼”ç¤º
        device="auto",
        save_dir="./qwen3_checkpoints",
        max_length=128
    )
    
    # 8. å¼€å§‹è®­ç»ƒ
    print("\nğŸ”¥ å¼€å§‹è®­ç»ƒ...")
    trainer.train(num_epochs=3, save_every=1, log_every=5)
    
    # 9. è¯„ä¼°æ¨¡å‹
    print("\nğŸ“ˆ è¯„ä¼°æ¨¡å‹...")
    eval_loss = trainer.eval()
    
    # 10. æµ‹è¯•æ–‡æœ¬ç”Ÿæˆ
    print("\nâœ¨ æµ‹è¯•æ–‡æœ¬ç”Ÿæˆ...")
    test_prompts = [
        "äººå·¥æ™ºèƒ½",
        "æœºå™¨å­¦ä¹ ",
        "æ·±åº¦å­¦ä¹ "
    ]
    
    for prompt in test_prompts:
        print(f"\næç¤º: {prompt}")
        generated = trainer.generate_text(prompt, max_length=50, temperature=0.7)
        print(f"ç”Ÿæˆ: {generated}")
    
    # 11. è·å–è®­ç»ƒç»Ÿè®¡
    print("\nğŸ“Š è®­ç»ƒç»Ÿè®¡ä¿¡æ¯:")
    stats = trainer.get_training_stats()
    print(f"  å½“å‰è½®æ•°: {stats['current_epoch']}")
    print(f"  æœ€ä½³æŸå¤±: {stats['best_loss']:.4f}")
    print(f"  æ€»è®­ç»ƒæ­¥æ•°: {stats['total_training_steps']}")
    print(f"  ä½¿ç”¨è®¾å¤‡: {stats['device']}")
    print(f"  è¯æ±‡è¡¨å¤§å°: {stats['vocab_size']}")
    print(f"  æœ€å¤§åºåˆ—é•¿åº¦: {stats['max_length']}")
    
    print("\nğŸ‰ Qwen3æ¨¡å‹è®­ç»ƒæ¼”ç¤ºå®Œæˆï¼")


def test_model_loading():
    """æµ‹è¯•æ¨¡å‹åŠ è½½åŠŸèƒ½"""
    print("\nğŸ”„ æµ‹è¯•æ¨¡å‹åŠ è½½åŠŸèƒ½...")
    
    try:
        # åˆ›å»ºæ–°çš„æ¨¡å‹å’Œè®­ç»ƒå™¨
        config = Qwen3Config.from_preset('tiny')
        model = Qwen3Transformer(config)
        optimizer = optim.AdamW(model.parameters(), lr=0.001)
        criterion = nn.CrossEntropyLoss()
        
        # åˆ›å»ºç®€å•çš„æ•°æ®é›†
        sample_texts = ["æµ‹è¯•æ–‡æœ¬"]
        tokenizer = SimpleTokenizer(vocab_size=1000)
        dataset = TextDataset(sample_texts, tokenizer, max_length=64)
        
        trainer = Qwen3Trainer(
            model=model,
            dataset=dataset,
            tokenizer=tokenizer,
            optimizer=optimizer,
            criterion=criterion,
            batch_size=1
        )
        
        # å°è¯•åŠ è½½æœ€ä½³æ¨¡å‹
        success = trainer.load("qwen3_checkpoints/qwen3_best_model.pt")
        
        if success:
            print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼")
            
            # æ˜¾ç¤ºè®­ç»ƒç»Ÿè®¡
            stats = trainer.get_training_stats()
            print(f"  å½“å‰è½®æ•°: {stats['current_epoch']}")
            print(f"  æœ€ä½³æŸå¤±: {stats['best_loss']:.4f}")
            
            # æµ‹è¯•æ¨ç†
            test_input = torch.randint(0, 100, (1, 64))
            with torch.no_grad():
                output = model(test_input)
            print(f"  æ¨¡å‹æ¨ç†æ­£å¸¸ï¼Œè¾“å‡ºå½¢çŠ¶: {output.shape}")
            
        else:
            print("âŒ æ¨¡å‹åŠ è½½å¤±è´¥ï¼")
            
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")


if __name__ == "__main__":
    main()
    
    # æµ‹è¯•æ¨¡å‹åŠ è½½
    test_model_loading()
